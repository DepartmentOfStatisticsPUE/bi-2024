---
title: "Metody quasi-randomizacyjne: post-stratyfikacja"
format: 
  html:
    self-contained: true
    table-of-contents: true
    number-sections: true
editor: visual
execute: 
  eval: true
  warning: false
  message: false
toc-title: Spis treści

lang: pl
---

# Wprowadzenie

Wczytujemy pakiet `tidyverse`.

```{r}
library(tidyverse)
library(knitr)
library(survey)
library(Hmisc) ## wtd.var to calculate weighted variance
```

Wczytujemy dane na potrzeby zajęć.

```{r}
dane <- read_csv("../data/popyt-zajecia-dane.csv")
```

```{r, echo=FALSE}
kable(head(dane))
```

# Przykłady

## Prosty przykład na potrzeby wykładów

1. Wyznaczamy wielkość populacji -- estymowana liczba wakatów.

```{r}
dane |>
  filter(!is.na(id_popyt)) |>
  count(klasa_pr, wt = wolne_miejsca*waga, name = "N") -> pop_data

```

```{r, echo=FALSE}
kable(pop_data)
```

2. Wyznaczamy odsetek wakatów oferowanych na jedną zmianę.

```{r}
dane |>
  filter(!is.na(id_cbop)) |> 
  group_by(klasa_pr) |>
  summarise(y = weighted.mean(jedna_zmiana, wolne_miejsca_cbop),
            y_var = wtd.var(jedna_zmiana, wolne_miejsca_cbop),
            n = sum(wolne_miejsca_cbop)) -> tab_cbop
```

```{r, echo=FALSE}
kable(tab_cbop)
```

3. Dodajemy informację o wielkości populacji.

```{r}
tab_cbop |>
  left_join(pop_data, by = "klasa_pr") |>
  mutate(W_h = N/sum(N))  -> tab_przyklad

```

```{r, echo=FALSE}
kable(tab_przyklad)
```

4. Wyznaczamy dwa estymatory odsetka wakatów oferowanych na jedną zmianę: `y_naive` -- zwykła średnia ze zbioru danych, `y_ps` -- estymator post-stratyfikowany. Wyznaczamy również wariancję zgodnie ze wzorem

$$
V\left(\bar{y}_{PS}\right)=\left(\frac{1}{n}-\frac{1}{N}\right) \sum_{h=1}^{L} W_{h} S_{h}^{2}+\frac{1}{n^{2}} \sum_{h=1}^{L}\left(1-W_{h}\right) S_{h}^{2}
$$



```{r}
tab_przyklad |>
  summarise(y_naive = weighted.mean(y, n),
            y_ps = sum(y*W_h),
            y_ps_var = (1/sum(n) - 1/sum(N))*sum(W_h*y_var) + 1/sum(n)^2*sum((1-W_h)*y_var),
            y_ps_sd = sqrt(y_ps_var)) -> wynik
```


```{r, echo=FALSE}
kable(wynik)
```

## Przykład z wykorzystaniem pakietu survey

1. Tworzymy podzbiór z potrzebnymi danymi, w której kolumnę `wolne_miejsca_cbop` traktujemy jako wagę wejściową ponieważ jeden wiersz odpowiada za jednen lub więcej wakatów. 

```{r}
dane |>
  filter(is.na(id_popyt)) |>
  select(id_jednostki, klasa_pr, sek, woj, zawod_kod2, wolne_miejsca_cbop, jedna_zmiana) |>
  mutate(jedna_zmiana=as.numeric(jedna_zmiana)) -> cbop_df
```


```{r, echo=FALSE}
kable(head(cbop_df))
```


2. Tworzymy obiekt `svydesign`

```{r}
cbop_svy <- svydesign(ids = ~1, 
                      weights = ~ wolne_miejsca_cbop,
                      data = cbop_df)
cbop_svy
```

3. Estymator naiwny na podstawie danych jednostkowych

```{r}
svymean(~jedna_zmiana, cbop_svy)
```

### Post-stratyfikacja z wykorzystaniem zmiennej `klasa_pr`

1. Wyznaczamy wartości globalne na potrzeby post-stratyfikacji zgodnie z wymogami funkcji `postStratify`

```{r}
pop_totals <- xtabs(wolne_miejsca*waga ~ klasa_pr, data= dane, subset = !is.na(id_popyt))
pop_totals
```

2. Dokonujemy post-stratyfikacji
```{r}
cbop_svy_ps <- postStratify(cbop_svy, strata = ~klasa_pr, population = pop_totals)
cbop_svy_ps
```

3. Estymator post-stratyfikacyjny

```{r}
svymean(~jedna_zmiana, cbop_svy_ps)
```


### Post-stratyfikacja z wykorzystaniem większej liczby zmiennych

1. Wyznaczamy wartości globalne na potrzeby post-stratyfikacji zgodnie z wymogami funkcji `postStratify` dla dwóch zmiennych

```{r}
pop_totals2 <- xtabs(wolne_miejsca*waga ~ klasa_pr + zawod_kod2, data= dane, subset = !is.na(id_popyt))
pop_totals2
```
2. Dokonujemy post-stratyfikacji z wykorzystaniem dwóch zmiennych

```{r}
cbop_svy_ps2 <- postStratify(cbop_svy, strata = ~klasa_pr + zawod_kod2, population = pop_totals2)
cbop_svy_ps2
```

3. Sprawdzamy czy uzyskane wagi odzwierciedlają wartości globalne `pop_totals2`

```{r}
svytable( ~klasa_pr + zawod_kod2, cbop_svy_ps2)
```
4. Możemy również porównać wagi wejściowe (przed post-stratyfikacją) z wagami końcowymi (po post-stratyfikacji).


```{r}
summary(weights(cbop_svy_ps2)/weights(cbop_svy))
```

```{r}
plot(weights(cbop_svy), weights(cbop_svy_ps2), xlab = "Wagi wejściowe (przed)", ylab = "Wagi wyjściowe (po)")
abline(a=0,b=1,col="red")
```

5. Estymator post-stratyfikacyjny

```{r}
svymean(~jedna_zmiana, cbop_svy_ps2)
```

# Badanie symulacyjne

## Definicja procesu generowania danych

Rozważmy następujący układ:

+ Wielkość populacji $N=10000$
+ Dwie cechy $X$:

$$
\begin{align}
X_1 & \sim \text{Bernoulli}(0.7) \\
X_2 & \sim \text{Bernoulli}(0.9)  \\
\end{align}
$$
+ Model dla cechy Y 

$$
Y = 4.5 - 3.5X_1 + 0.5X_2 + \epsilon; \quad \epsilon \sim N(0,1)
$$

+ Próba nielosowa o wielkości $n_b=1000$ jest generowana proporcjonalnie do cechy $Y$, gdzie prawdopodobieństwo wylosowania danego rekordu określone jest w następujący sposób:

$$
P(R_i = 1) = \frac{|y_i|}{\sum_{i=1}^N |y_i|}
$$
Dla tak uzyskanej próby nielosowej należy:

+ ocenić różnice w rozkładach X między próbą, a populacją,
+ ocenić zależność między cechą X1 i X2
+ dokonać post-stratyfikacji z wykorzystaniem pakietu `survey`.

## Rozwiązanie

Kod R do generowania danych

```{r}
set.seed(2023)
N <- 10000
nb <- 1000
X1 <- rbinom(N, 1, 0.7)
X2 <- rbinom(N, 1, 0.9)
Y <- 4.5 - 3.5*X1+0.5*X2 + rnorm(N)
nb_inds <- sample(1:N, size = nb, prob = abs(Y)/sum(abs(Y)))
flag <- 1:N %in% nb_inds
w_star <- N/nb ## dodajemy pseudo-wagę jako relację miedzy N / nb
df <- data.frame(Y,X1,X2,flag,w_star)
head(df)
```

Porównajmy rozkłady $X_1$ i $X_2$

```{r}
pop_X1 <- mean(df$X1)
pop_X2 <- mean(df$X2)
sam_X1 <- mean(df$X1[df$flag == 1])
sam_X2 <- mean(df$X2[df$flag == 1])
c(X1_pop = pop_X1, X2_pop = pop_X2, X1_proba = sam_X1, X2_proba = sam_X2)
```

Rozkład łączny $X_1$ i $X_2$ -- różnica w odsetkach między próbą, a populacją.

```{r}
prop.table(xtabs(~X1 + X2, df, subset = flag == T)) - prop.table(xtabs(~X1 + X2, df)) 
```
Jaka jest zależność między $Y$, a $X_1$ oraz $X_2$? 

```{r}
m1 <- lm(Y ~ X1 + X2, data = df, subset = flag == TRUE)
summary(m1)
```
Funkcją anova możemy sprawdzić jak dana zmienna wpływa na redukcję sumy kwadratów odchyleń (SSQ).

```{r}
anova(m1)
```

Wnioski:

+   główna rozbieżność w zmiennej $X_1$, w $X_2$ niezbyt,
+ zmienna $X_1$ jest silniej skorelowana z $Y$ niż $X_2$.

Dokonujemy post-stratyfikacji wg dwóch zmiennych

```{r}
totale <- xtabs(~X1 + X2, data = df)
dd <- svydesign(ids= ~1, weights = ~w_star, data = subset(df, flag == T))
dd2 <- postStratify(dd, strata= ~X1+X2, population = totale)
c(Y_prawda = mean(Y), Y_bez_ps = svymean(~Y, dd)[1], Y_ps = svymean(~Y, dd2)[1])
```

Jeżeli użyjemy wyłącznie $X_1$ uzyskamy następujące wyniki

```{r}
totale <- xtabs(~X1 , data = df)
dd <- svydesign(ids= ~1, weights = ~w_star, data = subset(df, flag == T))
dd2 <- postStratify(dd, strata= ~X1, population = totale)
c(Y_prawda = mean(Y), Y_bez_ps = svymean(~Y, dd)[1], Y_ps = svymean(~Y, dd2)[1])
```

Jeżeli użyjemy wyłącznie $X_2$ uzyskamy następujące wyniki


```{r}
totale <- xtabs(~X2 , data = df)
dd <- svydesign(ids= ~1, weights = ~w_star, data = subset(df, flag == T))
dd2 <- postStratify(dd, strata= ~X2, population = totale)
c(Y_prawda = mean(Y), Y_bez_ps = svymean(~Y, dd)[1], Y_ps = svymean(~Y, dd2)[1])
```

Wnioski:

+ użycie $X_1$ redukuje obciązenie, a $X_2$ nie wpływa na wyniki,
+ zredukowano obciążenie ale częściowo dlatego, że dobór próby był wyłącznie zależny od cechy Y, a nie od X1 i X2.

Wykonajmy to ćwiczenie 500 razy

```{r}
R <- 500
y_naive <- numeric(R)
y_ps <- numeric(R)
totale <- xtabs(~X1+X2 , data = df)
for (r in 1:500) {
  nb_inds <- sample(1:N, size = nb, prob = abs(Y)/sum(abs(Y)))
  flag <- 1:N %in% nb_inds
  w_star <- N/nb ## dodajemy pseudo-wagę jako relację miedzy N / nb
  df <- data.frame(Y,X1,X2,flag,w_star)
  
  dd <- svydesign(ids= ~1, weights = ~w_star, data = subset(df, flag == T))
  dd2 <- postStratify(dd, strata= ~X1+X2, population = totale)
  
  y_naive[r] <- svymean(~Y, dd)[1]
  y_ps[r] <- svymean(~Y, dd2)[1]
}

boxplot((cbind("Naiwny"=y_naive, "PS"=y_ps) - mean(Y))/mean(Y)*100, 
        xlab = "Estymator", ylab = "Relatywne obciążenie (w %)",
        ylim = c(0, 70))

```

Wyniki symulacji

```{r}
oszacowanie <- c(mean(y_naive), mean(y_ps))
obciazenie <- oszacowanie -mean(Y)
wariancja <- c(var(y_naive), var(y_ps))
rmse <- sqrt(obciazenie^2+wariancja)
data.frame(estymator=c("Naiwny", "PS"), oszacowanie, obciazenie, wariancja, rmse)
```

# Podsumowanie

+ Post-stratyfikacja wymaga znajomości wartości globalnych.
+ Post-stratyfikacja nie wymaga skomplikowanych procedur (można to zrobić w bazie SQL/MS Excel).
+ Estymator wariancji estymatora post-stratyfikacyjnego zakłada, że próba nielosowa jest próbą prostą z populacji.

